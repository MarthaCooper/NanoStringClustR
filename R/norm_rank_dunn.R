#' Ranks NanoString normalizations using cluster validity indices
#'
#' @description ranks NanoString normalisation by Dunn Index on euclidian
#' and correlation distances.
#'
#' @param count_set a normalised, count_set summarized experiment.
#'  Default = NULL
#' @param batch_aware TRUE or FALSE are rankings to be batch aware?
#' Default = FALSE.
#'
#' @examples
#'# biological groups
#' rnf5_group <- c(rep("WT", 5), rep("KO", 5))
#'
#' # sample ids
#' rnf5_sampleid <- c("GSM3638131", "GSM3638132", "GSM3638133", "GSM3638134",
#'                   "GSM3638135", "GSM3638136", "GSM3638137", "GSM3638138",
#'                   "GSM3638139", "GSM3638140")
#'
#' # build count_set
#' rnf5_count_set <- count_set(count_data = Rnf5,
#'                             group = rnf5_group,
#'                             samp_id = rnf5_sampleid)
#' # normalize
#' rnf5_count_set_norm <- multi_norm(count_set = rnf5_count_set,
#'                                   positive_control_scaling = TRUE,
#'                                   background_correct = "mean2sd")
#'                                   #plot_dir = "~/Dropbox/git/NanoStringClustR/plot_test/")
#' # rank normalizations
#' rnf5_eval <- norm_rank(rnf5_count_set_norm)
#'
#' @return plot and table of ranked normalizations
#'
#' @export norm_rank
#'
#' @importFrom clv cls.scatt.data clv.Dunn
#' @importFrom Biobase rowMedians
#' @importFrom reshape melt cast
#'
#'
#' @references
#'
#' Lukasz Nieweglowski (2013). clv: Cluster Validation Techniques. R package version 0.3-2.1.
#' https://CRAN.R-project.org/package=clv
#'


norm_rank <- function(count_set = count_set,
                      batch_aware = FALSE){

  ####### Input checks #######------------------------------------------------

  # check count_set is provided
  if(is.null(count_set)) stop("A count_set list generated by count_set must be provided.")



  if(!is.null(count_set)) {
    # check the file format
    if(count_set@class != "SummarizedExperiment"){
      stop(paste("summarized file provided is not a SummarizedExperiment,
                 Please produce a SummarizedExperiment using count_set.", "\n",
                 sep=""))
    }
  }

  # check that the count_set has been normalised
  if(length(names(assays(count_set))) == 1)
    stop("The count_set input must be normalised with multi_norm")

  #check batch aware is TRUE or FALSE
  if(!(is.logical(batch_aware))){
    stop("Batch_aware must be TRUE or FALSE")
  }

####### Input checks finished #######-----------------------------------------

### dunn indicies for groups ### -----------------------
  assays_all <- names(assays(count_set))

  all_group_dunns <- lapply(seq_along(assays_all), function (i){
    dunn_wrap(count_set = count_set,
              norm_method = assays_all[i],
              clusters = as.vector(as.integer((count_set$group))))
  })

  names(all_group_dunns) <- assays_all

  combined_group_dunns <- lapply(seq_along(names(all_group_dunns)), function(i){
    method_i <- all_group_dunns[[i]]
    method_i <- cbind(as.data.frame(method_i), rep(names(all_group_dunns)[i], 2))
    colnames(method_i) <- c("comp", "ave", "norm_method")
    method_i$intercluster <- rownames(method_i)
    return(method_i)
  })

  #tidy group_dunns dataframe
  combined_group_dunns <- do.call("rbind", combined_group_dunns)
  m_group_dunns <- reshape::melt(combined_group_dunns, id.vars = c("norm_method", "intercluster"))
  colnames(m_group_dunns)[3] <- "intracluster"
  m_group_dunns$combination <- paste(m_group_dunns$intercluster, m_group_dunns$intracluster, sep = "_")
  group_dunns <- m_group_dunns[m_group_dunns$combination %in% c("comp_comp", "ave_ave"), c(1,4,5)]
  group_dunns <- reshape::cast(group_dunns,  norm_method ~ combination)
  group_dunns$difference <- group_dunns$comp_comp - group_dunns$ave_ave
  group_dunns_ordered <- group_dunns[order(group_dunns$difference), ]
  group_dunns_ordered$group_dunn_rank <- c(1:nrow(group_dunns_ordered))

### variation around median RLE ### -------------------

  all_vars <- lapply(seq_along(assays_all), function(i){
    variation_around_med(count_set = count_set,
                         norm_method = assays_all[i])
  })

  names(all_vars) <- assays_all

  vars <- as.data.frame(do.call("rbind", all_vars))
  vars$norm_method <- rownames(vars)
  colnames(vars)[1] <- "sum_variation"
  vars_ordered <- vars[order(vars$sum_variation),]
  vars_ordered$variation_rank <- c(1:nrow(vars_ordered))

### dunn indicies for groups ### -----------------------

  if (batch_aware == FALSE){

  merged <- merge(vars_ordered, group_dunns_ordered, by = "norm_method")
  merged <- merged[, c(1,3,7)]
  merged$overall_rank <- merged$variation_rank + merged$group_dunn_rank
  merged_ordered <- merged[order(merged$overall_rank),]

  return(list("rankings" = merged_ordered,
              "sum_variation" = vars_ordered[,c(2,1,3)],
              "group_dunns" = group_dunns_ordered))

  }

  if (batch_aware == TRUE){

    batch_dunns <- lapply(seq_along(assays_all), function (i){
      dunn_wrap(count_set = count_set,
                norm_method = assays_all[i],
                clusters = as.vector(as.integer((count_set$batch))))
    })

    names(batch_dunns) <- assays_all

    combined_batch_dunns <- lapply(seq_along(names(batch_dunns)), function(i){
      method_i <- batch_dunns[[i]]
      method_i <- cbind(as.data.frame(method_i), rep(names(batch_dunns)[i], 2))
      colnames(method_i) <- c("comp", "ave", "norm_method")
      method_i$intercluster <- rownames(method_i)
      return(method_i)
    })

    #tidy group_dunns dataframe
    combined_batch_dunns <- do.call("rbind", combined_batch_dunns)
    m_batch_dunns <- reshape::melt(combined_batch_dunns, id.vars = c("norm_method", "intercluster"))
    colnames(m_batch_dunns)[3] <- "intracluster"
    m_batch_dunns$combination <- paste(m_batch_dunns$intercluster, m_batch_dunns$intracluster, sep = "_")
    batch_dunns <- m_batch_dunns[m_batch_dunns$combination %in% c("comp_comp", "ave_ave"), c(1,4,5)]
    batch_dunns <- reshape::cast(batch_dunns,  norm_method ~ combination)
    batch_dunns$difference <- batch_dunns$comp_comp - batch_dunns$ave_ave
    batch_dunns_ordered <- batch_dunns[order(batch_dunns$difference), ]
    batch_dunns_ordered$batch_dunn_rank <- c(nrow(batch_dunns_ordered):1) #best clustering between batches gets worse rank

    ### Overall rankings ####

    merged <- merge(vars_ordered, group_dunns_ordered, by = "norm_method")
    merged <- merge(merged, batch_dunns_ordered, by = "norm_method")
    merged <- merged[, c(1,3,7,11)]
    merged$overall_rank <- merged$variation_rank + merged$group_dunn_rank + merged$batch_dunn_rank
    merged_ordered <- merged[order(merged$overall_rank),]

    return(list("rankings" = merged_ordered,
                "sum_variation" = vars_ordered[,c(2,1,3)],
                "group_dunns" = group_dunns_ordered,
                "batch_dunns" = batch_dunns_ordered))
  }

}


######## function for dunn index ranking ####--------------------------------------

dunn_wrap <- function(count_set = count_set,
                      norm_method = "housekeeping_scaled",
                      clusters = as.vector(as.integer((count_set$group)))){

  get_counts <- paste0("assays(count_set)$", norm_method)
  data_in <- na.omit(eval(parse(text=get_counts)))

  cluster_data_euk <- clv::cls.scatt.data(t(data_in),
                                          clust = clusters,
                                          dist = "euclidean")

  #calculate all dunn indices
  intraclust = c("complete","average")
  interclust = c("complete", "average")

  dunn_data_euk <- clv::clv.Dunn(cluster_data_euk, intraclust, interclust)

  return(dunn_data_euk)

}

####### function for calculating sum variation around median RLE ##### --------------------


variation_around_med <- function(count_set = count_set,
                                 norm_method = "housekeeping_scaled"){

  get_counts <- paste0("assays(count_set)$", norm_method)
  data_in <- na.omit(eval(parse(text=get_counts)))

  #calculate median expression of each gene
  med_gene <- apply(data_in, 1, median)
  #calculate deviations from this median genecount-med_gene
  dev_from_med <- apply(data_in, 2, function(i) (i - med_gene))
  #calculate median deviations per sample - median of RLE plpot
  med <- apply(dev_from_med, 2, function(i) median(i))
  #sum absolute differences of the medians from 0
  sum_delta <- sum(abs(med))

  return(sum_delta)

}

####### function for generating rankings #######-------------------




